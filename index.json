[{"authors":["babak"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"477f320c1a5a8817f51ddab82b2be868","permalink":"https://mea-lab.github.io/author/babak-taati/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/babak-taati/","section":"authors","summary":"","tags":null,"title":"Babak Taati","type":"authors"},{"authors":["diego"],"categories":null,"content":"Diego L. Guarin is an Assistant Professor in the Biomedical Engineering program at the Florida Institue of Technology. His research interests include the application of machine learning and computer vision for assessing neurological diseases, and the development of novel signal processing approaches to study the human neuromuscular system. He is the director of the Movement Evaluation and Analysis Laboratory at Florida Tech.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6e05be09ebac4dbd9407c571fdc9dbe7","permalink":"https://mea-lab.github.io/author/diego-l.-guarin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/diego-l.-guarin/","section":"authors","summary":"Diego L. Guarin is an Assistant Professor in the Biomedical Engineering program at the Florida Institue of Technology. His research interests include the application of machine learning and computer vision for assessing neurological diseases, and the development of novel signal processing approaches to study the human neuromuscular system.","tags":null,"title":"Diego L. Guarin","type":"authors"},{"authors":["Gabriela_Acevedo"],"categories":null,"content":"Gabriela Acevedo is a Ph.D student in the Biomedical Engineering program at Florida Institute of Technology. She will be working as a graduate assistant in projects related with neuroscience and machine learning. She is interested in combining Neuroengineering with Computer Science to improve the diagnosis and treatment of different neurological disorders.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"78b214a6dc491a0e2be07dbd84f9813d","permalink":"https://mea-lab.github.io/author/gabriela-acevedo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/gabriela-acevedo/","section":"authors","summary":"Gabriela Acevedo is a Ph.D student in the Biomedical Engineering program at Florida Institute of Technology. She will be working as a graduate assistant in projects related with neuroscience and machine learning.","tags":null,"title":"Gabriela Acevedo","type":"authors"},{"authors":["Mariam_Chanie"],"categories":null,"content":"Mariam Chanie is a graduate student assistant working on a project to validate a device used to characterize the mechanical properties of the human ankle. She is interested in integrating electromechanical systems and biomechanics to develop medical devices for an application in cardiovascular and neuromuscular systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a0715558a16db8d048706ea7627ce224","permalink":"https://mea-lab.github.io/author/mariam-chanie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mariam-chanie/","section":"authors","summary":"Mariam Chanie is a graduate student assistant working on a project to validate a device used to characterize the mechanical properties of the human ankle. She is interested in integrating electromechanical systems and biomechanics to develop medical devices for an application in cardiovascular and neuromuscular systems.","tags":null,"title":"Mariam Chanie","type":"authors"},{"authors":["admin"],"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://mea-lab.github.io/author/nelson-bighetti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nelson-bighetti/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":["rob"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"17f79dadea841522d6c2fc0cef50c112","permalink":"https://mea-lab.github.io/author/robert-e.-kearney/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/robert-e.-kearney/","section":"authors","summary":"","tags":null,"title":"Robert E. Kearney","type":"authors"},{"authors":["Tessa"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"517d18ec21971f101184f5abc6bfa6b7","permalink":"https://mea-lab.github.io/author/tessa-a.-hadlock/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tessa-a.-hadlock/","section":"authors","summary":"","tags":null,"title":"Tessa A. Hadlock","type":"authors"},{"authors":["Yana"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4d0b9b7ac27376bff00d7271c0c034ea","permalink":"https://mea-lab.github.io/author/yana-yunusova/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yana-yunusova/","section":"authors","summary":"","tags":null,"title":"Yana Yunusova","type":"authors"},{"authors":[],"categories":[],"content":"","date":1589514050,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589514050,"objectID":"c636e8036903b3af3febf6ab1875a784","permalink":"https://mea-lab.github.io/project/my-project-name/","publishdate":"2020-05-14T23:40:50-04:00","relpermalink":"/project/my-project-name/","section":"project","summary":"","tags":[],"title":"My Project Name","type":"project"},{"authors":[],"categories":[],"content":"","date":1589513425,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589513425,"objectID":"fe859c6266641600992fd6a0d6f11947","permalink":"https://mea-lab.github.io/post/post1/","publishdate":"2020-05-14T23:30:25-04:00","relpermalink":"/post/post1/","section":"post","summary":"","tags":[],"title":"post","type":"post"},{"authors":["Diego L. Guarin","Aidan Dempster","Andrea Bandini","Yana Yunusova","Babak Taati"],"categories":["Facial Analysis"],"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"e8d990215beb6a0da1b8bbb652217dbf","permalink":"https://mea-lab.github.io/publication/2020e/","publishdate":"1969-12-31T19:33:40-05:00","relpermalink":"/publication/2020e/","section":"publication","summary":"Orofacial deficits are common in people with Parkinson's disease (PD) and their evolution might represent an important biomarker of disease progression. We are developing an automated system for assessment of orofacial function in PD that can be used in-home or in-clinic and can provide useful and objective clinical information that informs disease management. Our current approach relies on color and depth cameras for the estimation of 3D facial movements. However, depth cameras are not commonly available, might be expensive, and require specialized software for control and data processing. The objective of this paper was to evaluate if depth cameras are needed to differentiate between healthy controls and PD patients based on features extracted from orofacial kinematics. Results indicate that 2D features, extracted from color cameras only, are as informative as 3D features, extracted from color and depth cameras, differentiating healthy controls from PD patients. These results pave the way for the development of a universal system for automatic and objective assessment of orofacial function in PD.","tags":["Facial Analysis"],"title":"Estimation of Orofacial Kinematics in Parkinson's Disease: Comparison of 2D and 3D Markerless Systems for Motion Tracking","type":"publication"},{"authors":["Diego L. Guarin","Babak Taati","Tessa A. Hadlock","Yana Yunusova"],"categories":["Facial Analysis"],"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"76195a19bcd5fe72450ffd93e488b981","permalink":"https://mea-lab.github.io/publication/2020a/","publishdate":"1969-12-31T19:33:40-05:00","relpermalink":"/publication/2020a/","section":"publication","summary":" **Background** Automatic facial landmark localization in videos is an important first step in many computer vision applications, including the objective assessment of orofacial function. Convolutional neural networks (CNN) for facial landmarks localization are typically trained on faces of healthy and young adults, so model performance is inferior when applied to faces of older adults or people with diseases that affect facial movements, a phenomenon known as algorithmic bias. Fine-tuning pre-trained CNN models with representative data is a well-known technique used to reduce algorithmic bias and improve performance on clinical populations. However, the question of how much data is needed to properly fine-tune the model remains. **Methods** In this paper, we fine-tuned a popular CNN model for automatic facial landmarks localization using different number of manually annotated photographs from patients with facial palsy and evaluated the effects of the number of photographs used for model fine-tuning in the model performance by computing the normalized root mean squared error between the facial landmarks positions predicted by the model and those provided by manual annotators. Furthermore, we studied the effect of annotator bias by fine-tuning and evaluating the model with data provided by multiple annotators. **Results** Our results showed that fine-tuning the model with as little as 8 photographs from a single patient significantly improved the model performance on other individuals from the same clinical population, and that the best performance was achieved by fine-tuning the model with 320 photographs from 40 patients. Using more photographs for fine-tuning did not improve the model performance further. Regarding the annotator bias, we found that fine-tuning a CNN model with data from one annotator resulted in models biased against other annotators; our results also showed that this effect can be diminished by averaging data from multiple annotators. **Conclusions** It is possible to remove the algorithmic bias of a\textbf{depth} CNN model for automatic facial landmark localization using data from only 40 participants (total of 320 photographs). These results pave the way to future clinical applications of CNN models for the automatic assessment of orofacial function in different clinical populations, including patients with Parkinson’s disease and stroke.","tags":["Facial Analysis","Fairnes in AI","Facial Palsy","Deep-learning"],"title":"Automatic Facial Landmark Localization in Clinical Populations--Improving Model Performance with a Small Dataset","type":"publication"},{"authors":["Diego L. Guarin","Yana Yunusova","Babak Taati","Joseph R. Dusseldorp","Suresh Mohan","Joana Tavares","Martinus M. van Veen","Emily Fortier","Tessa A. Hadlock","and Nate Jowett"],"categories":["Facial Analysis"],"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"301a001bed99ddd0817b5ec1757eb4f9","permalink":"https://mea-lab.github.io/publication/2020b/","publishdate":"1969-12-31T19:33:40-05:00","relpermalink":"/publication/2020b/","section":"publication","summary":" **Importance** Quantitative assessment of facial function is challenging, and subjective grading scales such as House–Brackmann, Sunnybrook, and eFACE have well-recognized limitations. Machine learning (ML) approaches to facial landmark localization carry great clinical potential as they enable high-throughput automated quantification of relevant facial metrics from photographs and videos. However, the translation from research settings to clinical application still requires important improvements. **Objective** To develop a novel ML algorithm for fast and accurate localization of facial landmarks in photographs of facial palsy patients and utilize this technology as part of an automated computer-aided diagnosis system. **Design, Setting, and Participants** Portrait photographs of 8 expressions obtained from 200 facial palsy patients and 10 healthy participants were manually annotated by localizing 68 facial landmarks in each photograph and by 3 trained clinicians using a custom graphical user interface. A novel ML model for automated facial landmark localization was trained using this disease-specific database. Algorithm accuracy was compared with manual markings and the output of a model trained using a larger database consisting only of healthy subjects. **Main Outcomes and Measurements** Root mean square error normalized by the interocular distance (NRMSE) of facial landmark localization between prediction of ML algorithm and manually localized landmarks. **Results**\nPublicly available algorithms for facial landmark localization provide poor localization accuracy when applied to photographs of patients compared with photographs of healthy controls (NRMSE, 8.56 ± 2.16 vs. 7.09 ± 2.34, p ≪ 0.01). We found significant improvement in facial landmark localization accuracy for the facial palsy patient population when using a model trained with a relatively small number photographs (1440) of patients compared with a model trained using several thousand more images of healthy faces (NRMSE, 6.03 ± 2.43 vs. 8.56 ± 2.16, p ≪ 0.01). **Conclusions and Relevance**\nRetraining a computer vision facial landmark detection model with fewer than 1600 annotated images of patients significantly improved landmark detection performance in frontal view photographs of this population. The new annotated database and facial landmark localization model represent the first steps toward an automatic system for computer-aided assessment in facial palsy. ","tags":["Facial Analysis","Computer-based diagnosis","Facial Palsy"],"title":"Toward an automatic system for computer-aided assessment in facial palsy","type":"publication"},{"authors":["Ronit Malka","Diego L. Guarin","Suresh Mohan","Ivan Coto Hernandez","Pavel Gorelik","Ofer Mazor","Tessa A. Hadlock","and Nate Jowett"],"categories":["Rodent Model"],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"2c25f93bd5d79bd1d81575160538dd26","permalink":"https://mea-lab.github.io/publication/2020c/","publishdate":"1969-12-31T19:33:40-05:00","relpermalink":"/publication/2020c/","section":"publication","summary":" **Background**\nDisease processes causing increased neural compartment pressure may induce transient or permanent neural dysfunction. Surgical decompression can prevent and reverse such nerve damage. Owing to insufficient evidence from controlled studies, the efficacy and optimal timing of decompression surgery remains poorly characterized for several entrapment syndromes. **New method**\nWe describe the design, manufacture, and validation of a device for study of entrapment neuropathy in a small animal model. This device applies graded extrinsic pressure to a peripheral nerve and wirelessly transmits applied pressure levels in real-time. We implanted the device in rats applying low (under 100 mmHg), intermediate (200–300 mmHg) and high (above 300 mmHg) pressures to induce entrapment neuropathy of the facial nerve to mimic Bell’s palsy. Facial nerve function was quantitatively assessed by tracking whisker displacements before, during, and after compression. **Results**\nAt low pressure, no functional loss was observed. At intermediate pressure, partial functional loss developed with return of normal function several days after decompression. High pressure demonstrated complete functional loss with incomplete recovery following decompression. Histology demonstrated uninjured, Sunderland grade III, and Sunderland grade V injury in nerves exposed to low, medium, and high pressure, respectively. **Comparison with existing methods**\nExisting animal models of entrapment neuropathy are limited by inability to measure and titrate applied pressure over time. **Conclusions**\nDescribed is a miniaturized, wireless, fully implantable device for study of entrapment neuropathy in a murine model, which may be broadly employed to induce various degrees of neural dysfunction and functional recovery in live animal models.","tags":["Facial Palsy","Rodent Model"],"title":"Implantable wireless device for study of entrapment neuropathy","type":"publication"},{"authors":["Jacqueline J. Greene","Diego L. Guarin","Joana Tavares","Emily Fortier","Mara Robinson","Joseph R. Dusseldorp","Olivia Quatela","Nate Jowett","Tessa A. Hadlock"],"categories":["Facial Analysis"],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"50dd133dab2e07461227c7174f25405f","permalink":"https://mea-lab.github.io/publication/2020d/","publishdate":"1969-12-31T19:33:40-05:00","relpermalink":"/publication/2020d/","section":"publication","summary":" **Objectives**\nFacial palsy causes variable facial disfigurement ranging from subtle asymmetry to crippling deformity. There is no existing standard database to serve as a resource for facial palsy education and research. We present a standardized set of facial photographs and videos representing the entire spectrum of flaccid and nonflaccid (aberrantly regenerated or synkinetic) facial palsy. To demonstrate the utility of the dataset, we describe the relationship between level of facial function and perceived emotion expression as determined by an automated emotion detection, machine learning‐based algorithm. **Methods**\nPhotographs and videos of patients with both flaccid and nonflaccid facial palsy were prospectively gathered. The degree of facial palsy was quantified using eFACE, House‐Brackmann, and Sunnybrook scales. Perceived emotion during a standard video of facial movements was determined using an automated, machine learning algorithm. **Results**\nSixty participants were enrolled and categorized by eFACE score across the range of facial function. Patients with complete flaccid facial palsy (eFACE ","tags":["Facial Analysis","Facial Palsy"],"title":"The spectrum of facial palsy: The MEEI facial palsy photo and video standard set","type":"publication"},{"authors":["Joseph R. Dusseldorp","Martinus M. van Veen","Diego L. Guarin","Olivia Quatela","Nate Jowett, and","Tessa A. Hadlock"],"categories":["Facial Analysis"],"content":"","date":1574294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574294400,"objectID":"50b3d9dd4429b0077bb39fdbd11c05cb","permalink":"https://mea-lab.github.io/publication/2019a/","publishdate":"1969-12-31T19:33:39-05:00","relpermalink":"/publication/2019a/","section":"publication","summary":" **Importance**\nSurgeons have sought to optimize outcomes of smile reanimation surgery by combining inputs from nerve-to-masseter and cross-face nerve grafts. An objective assessment tool could help surgeons evaluate outcomes to determine the optimal neural sources for smile reanimation. **Objective**\nTo evaluate the use of a novel video time-stamping method and standard outcome measurement tools to assess outcomes of facial reanimation surgery using various innervation strategies. **Design, Setting, and Participants**\nCohort study assessing the outcomes of dually innervated gracilis free muscle transfers vs single-source innervated gracilis transfer performed at a tertiary care facial nerve center between 2007 and 2017 using a novel, video time-stamping spontaneity assessment method. The statistical analyses were performed in 2018. **Interventions**\nDually innervated gracilis free muscle transfers or single-source innervated gracilis transfer. **Main Outcomes and Measures**\nSpontaneous smiling was assessed by clinicians and quantified using blinded time-stamped video recordings of smiling elicited while viewing humorous video clips. **Results**\nThis retrospective cohort study included 25 patients (12 men and 13 women; median [range] age, 38.4 [29.3-46.0] years) treated with dually innervated gracilis free functional muscle graft for unilateral facial palsy between 2007 and 2017. Smile spontaneity assessment was performed in 17 patients and was compared with assessment performed in 24 patients treated with single-source innervated gracilis transfer (ie, nerve-to-masseter–driven or cross-face nerve graft–driven gracilis [n = 13]) (demographic data not available for NTM and CFNG cohorts). The use of time-stamped video assessment revealed that spontaneous synchronous oral commissure movement in a median percentage of smiles was 33% in patients with dually innervated gracilis (interquartile range [IQR], 0%-71%), 20% of smiles in patients with nerve-to-masseter–driven gracilis (IQR, 0%-50%), and 75% of smiles in patients with cross-face nerve graft–driven gracilis (IQR, 0%-100%). Clinicians graded smile spontaneity in dually innervated cases as absent in 40% (n = 6 of 15), trace in 33% (n = 5 of 15) and present in 27% (n = 4 of 15). No association was demonstrated between clinician-reported spontaneity and objectively measured synchronicity. **Conclusions and Relevance**\nDually innervated gracilis free muscle transfers may improve smile spontaneity compared with masseteric nerve–driven transfers but not to the level of cross-face nerve graft–driven gracilis transfers. Quantifying spontaneity is notoriously difficult, and most authors rely on clinical assessment. Our results suggest that clinicians may rate presence of spontaneity higher than objective measures, highlighting the importance of standardized assessment techniques. ","tags":["Facial Palsy"],"title":"Spontaneity Assessment in Dually Innervated Gracilis Smile Reanimation Surgery","type":"publication"},{"authors":["Jacqueline J. Greene","Joana Tavares","Diego L. Guarin","Tessa A. Hadlock"],"categories":["Facial Analysis"],"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"47dd39c78fda4421b2a17261d8201f66","permalink":"https://mea-lab.github.io/publication/2019c/","publishdate":"1969-12-31T19:33:39-05:00","relpermalink":"/publication/2019c/","section":"publication","summary":" **Importance**\nQuantitative assessment of facial function is difficult, and historic grading scales such as House-Brackmann have well-recognized limitations. The electronic, clinician-graded facial function scale (eFACE) allows rapid regional analysis of static, dynamic, and synkinetic facial function in patients with unilateral facial palsy within the course of a clinical encounter, but it relies on clinician assessment. A newly developed, machine-learning algorithm (Emotrics) provides automated, objective facial measurements but lacks clinical input (ie, recognizing laterality of facial palsy or synkinesis). **Objectives**\nTo compare the sensitivity of a clinician-based tool (eFACE) to a well-established intervention for facial palsy (eyelid weight placement) with an automated facial-measurement algorithm (Emotrics). **Design, setting, and participants**\nA retrospective review was conducted of the most recent 53 patients with unilateral facial palsy who received an eyelid weight at the Massachusetts Eye and Ear Infirmary Facial Nerve Center from 2014 to 2017. Preoperative and postoperative photographs were deidentified and randomized. The entire cohort was analyzed by 3 clinicians, as well as by the Emotrics program. **Main outcomes and measures**\neFACE scores of the palpebral fissure at rest (0, wide; 100, balanced; 200, narrow), with gentle eyelid closure (0, incomplete; 100, complete), and with forceful eyelid closure (0, incomplete; 100, complete) before and after eyelid weight placement were compared with palpebral fissure measurements by Emotrics. **Results**\nOf the 53 participants, 33 were women, and mean (SD) age was 44.7 (18) years. The mean (SD) eFACE scores and Emotrics measurements (in millimeters) before vs after eyelid weight placement of the palpebral fissure at rest (eFACE, 84.3 [15.9] vs 109.7 [21.4]; Emotrics, 10.3 [2.2] vs 9.1 [1.8]), with gentle eyelid closure (eFACE, 65.9 [28.0] vs 92.1 [15.4]; Emotrics, 4.4 [2.7] vs 1.3 [2.0]), and with forceful eyelid closure (eFACE, 75.1 [28.6] vs 97.0 [10.7]; Emotrics, 3.0 [3.1] vs 0.5 [1.3]) all significantly improved. Subgroup analysis of patients with expected recovery (eg, Bell palsy) (n = 40) demonstrated significant development of ocular synkinesis on eFACE (83.9 [22.7] vs 98.9 [4.4]) after weight placement, which could also explain the improvement in eyelid function. The scores of patients with no expected recovery (n = 13) improved in both eFACE and Emotrics analysis following eyelid weight placement, though results did not reach significance, likely limited by the small subgroup size. **Conclusions and relevance**\nThe eFACE tool agrees well with automated, objective facial measurements using a machine-learning based algorithm such as Emotrics. The eFACE tool is sensitive to spontaneous recovery and surgical intervention, and may be used for rapid regional facial function assessment from a clinician's perspective following recovery and/or surgical intervention.;h ","tags":["Facial Analysis","Facial Palsy"],"title":"Clinician and Automated Assessments of Facial Function Following Eyelid Weight Placement","type":"publication"},{"authors":["Joseph R. Dusseldorp","Diego L. Guarin","Martinus M. van Veen","Nate Jowett","Tessa A. Hadlock"],"categories":["Facial Analysis"],"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"b91143a0df22daa3ca8e1a6011637a92","permalink":"https://mea-lab.github.io/publication/2019b/","publishdate":"1969-12-31T19:33:39-05:00","relpermalink":"/publication/2019b/","section":"publication","summary":" **Background**\nTools to quantify layperson assessments of facial palsy are lacking. In this study, artificial intelligence was applied to develop a proxy for layperson assessments, and compare sensitivity to existing outcome measures. **Methods**\nArtificially intelligent emotion detection software was used to develop the emotionality quotient. The emotionality quotient was defined as the percentage probability of perceived joy over the percentage probability of perceived negative emotions during smiling, as predicted by the software. The emotionality quotient was used to analyze the emotionality of voluntary smiles of normal subjects and unilateral facial palsy patients before and after smile reanimation. The emotionality quotient was compared to oral commissure excursion and layperson assessments of facial palsy patients. **Results**\nIn voluntary smiles of 10 normal subjects, 100 percent joy and no negative emotion was detected (interquartile ranges, 0/1). Median preoperative emotionality quotient of 30 facial palsy patients was 15/-60 (interquartile range, 73/62). Postoperatively, median emotionality quotient was 84/0 (interquartile range, 28/5). In 134 smile reanimation patients, no correlation was found between postoperative oral commissure excursion and emotionality quotient score. However, in 61 preoperative patients, a moderate correlation was found between layperson-assessed disfigurement and negative emotion perception (correlation coefficient, 0.516; p ","tags":["Facial Analysis","Facial Palsy","Computer-based Diagnosis"],"title":"In the eye of the beholder: Changes in perceived emotion expression after smile reanimation","type":"publication"},{"authors":["Diego L. Guarin","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1536624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536624000,"objectID":"654dd482eefd08362e5401ea5ccfef3a","permalink":"https://mea-lab.github.io/publication/2018b/","publishdate":"1969-12-31T19:33:38-05:00","relpermalink":"/publication/2018b/","section":"publication","summary":" The overall mechanical properties of a joint are generated by a combination intrinsic (mechanical) and reflex (neural) mechanisms. Nevertheless, many methods for estimating joint mechanical properties have used a linear dynamic model whose parameters are commonly related to the joint inertial and visco-elastic properties. Such mechanical models cannot account for torques due to reflex mechanisms and consequently fitting them to data containing reflex torques can give biased results. This paper addresses this issue in two ways. First, using simulation studies, it demonstrates that fitting linear dynamic models in the presence of reflex torques will indeed provide biased estimates of intrinsic joint properties; the bias is significant for small reflex torques and increases proportionally with reflex torque magnitude. Second, it develops and validates a novel approach to accurately estimate the time-varying, intrinsic mechanical properties of a joint in the presence of reflex torques. The approach involves applying small position perturbations to the joint trajectory and then applying novel mathematical models and system identification techniques to analytically separate the measured total joint torque into its intrinsic and reflex components. The method first estimates a non-parametric, reflex electromyography-torque model, and uses it to predict the reflex torques which is subtracted from the total torque. Then, it estimates a non-parametric, linear, and time-varying model of the intrinsic mechanical properties from the residuals. Simulation results demonstrate that the new approach accurately tracks time-varying joint intrinsic mechanical properties during movement independently of the reflex torque magnitude. The new algorithm will be a useful tool in the study of motor control, as it supports the unbiased estimation of joint intrinsic mechanical properties during movement in the presence of reflex torques.","tags":["Joint Stiffness","System Identification","Time-Varying Systems"],"title":"Unbiased estimation of human joint intrinsic mechanical properties during movement","type":"publication"},{"authors":["Diego L. Guarin","Joseph R. Dusseldorp","Tessa A. Hadlock","Nate Jowett"],"categories":["Facial Analysis"],"content":"","date":1531958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531958400,"objectID":"8912e13d1b42bc7584e758ece22c1f82","permalink":"https://mea-lab.github.io/publication/2018a/","publishdate":"1969-12-31T19:33:38-05:00","relpermalink":"/publication/2018a/","section":"publication","summary":"","tags":["Facial Analysis","Facial Palsy"],"title":"A machine learning approach for automated facial measurements in facial palsy","type":"publication"},{"authors":["Diego L. Guarin","Robert E. Kearney"],"categories":["Time-Varying Systems"],"content":"","date":1503100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503100800,"objectID":"a89ffc83e0729b12c59cffbfa0af3830","permalink":"https://mea-lab.github.io/publication/2017b/","publishdate":"1969-12-31T19:33:37-05:00","relpermalink":"/publication/2017b/","section":"publication","summary":"The mechanical properties of a joint are determined by the combination of intrinsic and reflex mechanisms. However, in some situations the reflex contributions are small so that intrinsic mechanisms play the dominant role in the control of posture and movement. The intrinsic mechanisms, characterized by the joint compliance, can be described well by a second order, linear model for small perturbations around an operating point defined by mean position and torque. However, the compliance parameters depend strongly on the operating point. Thus, for functional activities, such as walking, where position and torque undergo large, rapid changes, the joint compliance will also present large, fast changes and so will appear to be Time-Varying (TV). Therefore, a TV system identification algorithm must be used to characterize these changes. This paper introduces a novel TV system identification algorithm that achieves this. The method extends an instrumental-variable based algorithm for the identification of linear, TV, parametric, Box-Jenkins models to use periodic data. Simulation studies demonstrate that the new algorithm accurately tracks the changes in intrinsic joint compliance expected during walking. Moreover, the method performs well with the complex noise encountered in practice. Consequently the new method should be a valuable tool for the study of joint mechanics during functional activities.","tags":["System Identification","Time-Varying Systems"],"title":"Identification of a time-varying, box-jenkins model of intrinsic joint compliance","type":"publication"},{"authors":["Diego L. Guarin","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1497830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497830400,"objectID":"c19feee7388cd334d42021961329cbd7","permalink":"https://mea-lab.github.io/publication/2017a/","publishdate":"1969-12-31T19:33:37-05:00","relpermalink":"/publication/2017a/","section":"publication","summary":"Dynamic joint stiffness determines the relation between joint position and torque, and plays a vital role in the control of posture and movement. Dynamic joint stiffness can be quantified during quasi-stationary conditions using disturbance experiments, where small position perturbations are applied to the joint and the torque response is recorded. Dynamic joint stiffness is composed of intrinsic and reflex mechanisms that act and change together, so that nonlinear, mathematical models and specialized system identification techniques are necessary to estimate their relative contributions to overall joint stiffness. Quasi-stationary experiments have demonstrated that dynamic joint stiffness is heavily modulated by joint position and voluntary torque. Consequently, during movement, when joint position and torque change rapidly, dynamic joint stiffness will be Time-Varying (TV). This paper introduces a new method to quantify the TV intrinsic and reflex components of dynamic joint stiffness during movement. The algorithm combines ensemble and deterministic approaches for estimation of TV systems; and uses a TV, parallel-cascade, nonlinear system identification technique to separate overall dynamic joint stiffness into intrinsic and reflex components from position and torque records. Simulation studies of a stiffness model, whose parameters varied with time as is expected during walking, demonstrated that the new algorithm accurately tracked the changes in dynamic joint stiffness using as little as 40 gait cycles. The method was also used to estimate the intrinsic and reflex dynamic ankle stiffness from an experiment with a healthy subject during which ankle movements were imposed while the subject maintained a constant muscle contraction. The method identified TV stiffness model parameters that predicted the measured torque very well, accounting for more than 95% of its variance. Moreover, both intrinsic and reflex dynamic stiffness were heavily modulated through the movement in a manner that could not be predicted from quasi-stationary experiments. The new method provides the tool needed to explore the role of dynamic stiffness in the control of movement.","tags":["Joint Stiffness","System Identification","Time-Varying Systems"],"title":"Estimation of time-varying, intrinsic and reflex dynamic joint stiffness during movement. Application to the ankle joint","type":"publication"},{"authors":["Diego L. Guarin"],"categories":["Joint Stiffnes"],"content":"","date":1485907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1485907200,"objectID":"8894549ecf8ddff61497837e818c9828","permalink":"https://mea-lab.github.io/thesis/phddiego/","publishdate":"1969-12-31T19:33:37-05:00","relpermalink":"/thesis/phddiego/","section":"thesis","summary":"","tags":["Joint Stiffness","System Identification"],"title":"Identification of Dynamic Ankle Stiffness during Time-Varying Conditions","type":"thesis"},{"authors":["Diego L. Guarin","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1438387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438387200,"objectID":"18fb7c8eb1195239e346529213a4a193","permalink":"https://mea-lab.github.io/publication/2015b/","publishdate":"1969-12-31T19:33:35-05:00","relpermalink":"/publication/2015b/","section":"publication","summary":"This paper introduces an iterative algorithm for the identification of time-varying (TV)-Hammerstein systems. This system is composed by a TV static nonlinearity followed by a TV Box-Jenkins linear model. The algorithm uses two basis function expansions: one to represent the TV parameters and a second to approximate the output of the static nonlinearity. A simulation study showed that the algorithm accurately identified the shape of the TV static nonlinearity and linear dynamic elements even though the noise model structure was unknown.","tags":["System Identification","Time-Varying Systems"],"title":"An instrumental variable approach for the identification of time-varying, Hammerstein systems","type":"publication"},{"authors":["Ehsan Sobhani-Tehrani","Mahsa Golka","Diego L. Guarin","Kian Jalaleddini","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1438387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438387200,"objectID":"ff747a31c70bb1075b548efe35c78d9f","permalink":"https://mea-lab.github.io/publication/2015c/","publishdate":"1969-12-31T19:33:35-05:00","relpermalink":"/publication/2015c/","section":"publication","summary":"The Hammerstein system provides a good model for the stretch reflex contribution to joint stiffness under quasi-stationary conditions. However, the model parameters change dramatically with the operating point defined by the joint angular position and muscle activation. Both position and activation level undergo large, rapid changes during movement and consequently reflex stiffness will be timevarying. Our laboratory has developed a series of algorithms to identify time-varying Hammerstein systems using approaches involving: large input-output ensembles, multiple short segments, temporal expansion, and linear parameter variation. This paper reviews these methods and evaluates their relative strengths and weaknesses.","tags":["System Identification","Time-Varying Systems"],"title":"Methods for the Identification of Time-Varying Hammerstein Systems with Applications to the Study of Dynamic Joint Stiffness","type":"publication"},{"authors":["Kian Jalaleddini","Mahsa Golka","Diego L. Guarin","Ehsan Sobhani-Tehrani","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1438387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438387200,"objectID":"59024292a20abc3ba5c934e4c2f070b9","permalink":"https://mea-lab.github.io/publication/2015d/","publishdate":"1969-12-31T19:33:35-05:00","relpermalink":"/publication/2015d/","section":"publication","summary":"Joint stiffness has been extensively used to study joint biomechanics. It can be described by a block-oriented, nonlinear, parallel-cascade structure under quasi-stationary conditions defined by the joint operating point. The model parameters are modulated dramatically during functional tasks where the joint operating point is varied with time. This paper reviews three parametric methods developed by our laboratory to identify joint stiffness: a refined instrumental variable method for transfer function identification of time-invariant stiffness, a MOESP subspace method for state-space identification of time-invariant stiffness, and a linear parameter varying subspace method for time-varying stiffness. The effectiveness of each method is demonstrated using experimental data recorded during posture and movement.","tags":["System Identification","Time-Varying Systems","Joint Stiffness"],"title":"Parametric methods for identification of time-invariant and time-varying joint stiffness models","type":"publication"},{"authors":["Diego L. Guarin","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1438387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438387200,"objectID":"005f219b1044fec5139f44c887ce2cf2","permalink":"https://mea-lab.github.io/publication/2015a/","publishdate":"1969-12-31T19:33:35-05:00","relpermalink":"/publication/2015a/","section":"publication","summary":"Dynamic joint stiffness defines the torque generated at the joint in response to position perturbations. Dynamic stiffness is modulated by the angular position and the muscle activation level, making it difficult to estimate during large movements and/or time-varying muscle contractions. This paper presents a new methodology for estimating dynamic joint stiffness during movement and muscle activation. For this, we formulate a novel, nonlinear, dynamic joint stiffness model and present a new algorithm to estimate its parameters. The algorithm assumes that the variability in the model parameters is a function of the mean joint position. Using this methodology we estimated the dynamic joint stiffness at the ankle throughout ramp and hold displacements during a constant muscle contraction. The estimated model accurately predicted the intrinsic and reflex torques produced at the ankle as a response to small position perturbations during large displacement with muscle activation. Preliminary results show that during muscle contraction, ankle intrinsic stiffness estimated during movement is significantly lower than that estimated during quasi-stationary experiments.","tags":["Joint Stiffness","System Identification","Time-Varying Systems"],"title":"Time-varying identification of ankle dynamic joint stiffness during movement with constant muscle activation","type":"publication"},{"authors":["Diego L. Guarin","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1406851200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406851200,"objectID":"59f3fadf7d8103230a0ee2509438afd7","permalink":"https://mea-lab.github.io/publication/2014a/","publishdate":"1969-12-31T19:33:34-05:00","relpermalink":"/publication/2014a/","section":"publication","summary":"Generation of torque around a joint usually involves the activation of several agonist muscles and may also involve the co-activation of antagonist muscles. Therefore, a valid model for the dynamic relation between surface EMG (an indirect measured of the muscle's neural input) and the torque should take the form of a Multiple-Input/Single-Output (MISO) system to account for the contributions of the different muscles. This paper presents a new method to accurately estimate the dynamic EMG/Torque relation when multiple muscles are active simultaneously. Using our method we found that flexor and extensor muscles at the ankle have different dynamic properties.","tags":["System Identification","EMG"],"title":"Multiple-input/single-output identification of the dynamic relation between EMG and torque at the human ankle during isometric contractions","type":"publication"},{"authors":["Mina Ranjbaran","Kian Jalaleddini","Diego L. Guarin","Robert E. Kearney","Henrietta Galiana"],"categories":["Joint Stiffnes"],"content":"","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"dc19cd1f636c255caaef4288d09ac83a","permalink":"https://mea-lab.github.io/publication/2013b/","publishdate":"1969-12-31T19:33:33-05:00","relpermalink":"/publication/2013b/","section":"publication","summary":"Noise characteristics play an important role in evaluating tools developed to study biomedical systems. Despite usual assumptions, noise in biomedical systems is often nonwhite or non-Gaussian. In this paper, we present a method to analyze the noise component of a biomedical system. We demonstrate the effectiveness of the method in the analysis of noise in voluntary ankle torque measured by a torque transducer and eye movements measured by electro-oculography (EOG).","tags":["System Identification"],"title":"Analysis and modeling of noise in biomedical systems","type":"publication"},{"authors":["Diego L. Guarin","Kian Jalaleddini","Robert E. Kearney"],"categories":["Joint Stiffnes"],"content":"","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"0f9e18f9df956b531a89b165fb48eb19","permalink":"https://mea-lab.github.io/publication/2013a/","publishdate":"1969-12-31T19:33:33-05:00","relpermalink":"/publication/2013a/","section":"publication","summary":"Dynamic ankle joint stiffness defines the relationship between the position of the ankle and the torque acting about it and can be separated into intrinsic and reflex components. Under stationary conditions, intrinsic stiffness can described by a linear second order system while reflex stiffness is described by Hammerstein system whose input is delayed velocity. Given that reflex and intrinsic torque cannot be measured separately, there has been much interest in the development of system identification techniques to separate them analytically. To date, most methods have been nonparametric and as a result there is no direct link between the estimated parameters and those of the stiffness model. This paper presents a novel algorithm for identification of a discrete-time model of ankle stiffness. Through simulations we show that the algorithm gives unbiased results even in the presence of large, non-white noise. Application of the method to experimental data demonstrates that it produces results consistent with previous findings.","tags":["Joint Stiffness","System Identification"],"title":"Identification of a parametric, discrete-time model of ankle stiffness","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://mea-lab.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://mea-lab.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"widget_page"}]